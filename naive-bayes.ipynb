{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns;\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from torch.nn.functional import softplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n",
    "\n",
    "we will use the 20 newsgroups dataset. example usage of this data can be found [here](http://scikit-learn.org/stable/datasets/index.html#the-20-newsgroups-text-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab():\n",
    "    with open('./simple-vocab.txt')as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    return np.unique(content)\n",
    "vocab = get_vocab()\n",
    "num_features = len(vocab)\n",
    "categories = [\n",
    "    'rec.autos',\n",
    "    'rec.sport.baseball', \n",
    "    'rec.sport.hockey',\n",
    "    'sci.med', \n",
    "    'sci.space'\n",
    "]\n",
    "num_cats = len(categories)\n",
    "docs_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "docs_test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature extraction\n",
    "\n",
    "see wikipedia for an explaination of [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (2978, 1027)\n",
      "test: (1982, 1027)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english', \n",
    "    vocabulary=vocab,\n",
    "    binary=True, \n",
    "    use_idf=False, \n",
    "    norm=None\n",
    ")\n",
    "vectors_train = vectorizer.fit_transform(docs_train.data).toarray()\n",
    "vectors_test = vectorizer.transform(docs_test.data).toarray()\n",
    "print('train: {}'.format(vectors_train.shape))\n",
    "print('test: {}'.format(vectors_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def model(dataX, dataY):\n",
    "    cat_prior = pyro.sample(\n",
    "        'cat_prior',\n",
    "        dist.Dirichlet(torch.tensor([1.,1.,1.,1.,1.,1.]))\n",
    "    )\n",
    "    with pyro.iarange('data_loop', dataX.size(0)):\n",
    "        cat_params = torch.ones(dataX.size(0), 6) * cat_prior \n",
    "        cat = pyro.sample(\n",
    "            'cat', \n",
    "            dist.Categorical(cat_params).independent(1)\n",
    "        )\n",
    "        \n",
    "        incorrect = dataY != cat\n",
    "       \n",
    "        for j in pyro.irange('likelihood_loop', dataX.size(1)):\n",
    "            c0 = torch.ones(dataX.size(0))\n",
    "            c1 = torch.ones(dataX.size(0))\n",
    "            beta = pyro.sample(\n",
    "                'beta_{}'.format(j),\n",
    "                dist.Beta(c0, c1).independent(1)\n",
    "            )\n",
    "            # use dataY and cat.item to mask out entries of beta\n",
    "            beta[incorrect] = 1e-5 \n",
    "            \n",
    "            pyro.sample(\n",
    "                'bern_{}'.format(j),\n",
    "                dist.Bernoulli(beta),\n",
    "                obs=dataX[:,j]\n",
    "            )\n",
    "\n",
    "def model_guide(dataX, dataY):\n",
    "    cat_prior = pyro.sample(\n",
    "        'cat_prior',\n",
    "        dist.Dirichlet(torch.tensor([1.,1.,1.,1.,1.,1.]))\n",
    "    )\n",
    "    with pyro.iarange('data_loop', dataX.size(0)):\n",
    "        cat_params = torch.ones(dataX.size(0), 6) * cat_prior \n",
    "        cat = pyro.sample(\n",
    "            'cat', \n",
    "            dist.Categorical(cat_params).independent(1)\n",
    "        )\n",
    "        \n",
    "        for j in pyro.irange('likelihood_loop', dataX.size(1)):\n",
    "            c0 = torch.ones(dataX.size(0))\n",
    "            c1 = torch.ones(dataX.size(0))\n",
    "            beta = pyro.sample(\n",
    "                'beta_{}'.format(j),\n",
    "                dist.Beta(c0, c1).independent(1)\n",
    "            )\n",
    "\n",
    "trainx_t = torch.Tensor(vectors_train)\n",
    "trainy_t = torch.LongTensor(docs_train.target)\n",
    "posterior = pyro.infer.Importance(model, guide=model_guide, num_samples=10)\n",
    "marginal = pyro.infer.EmpiricalMarginal(posterior.run(trainx_t, trainy_t), sites='beta_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4922,  0.8754,  0.9402,  0.3103,  0.5383,  0.2120,  0.7439,\n",
       "         0.3543,  0.3455,  0.1926,  0.4914,  0.9535,  0.1431,  0.5067,\n",
       "         0.6839,  0.9996,  0.1553,  0.2333,  0.2196,  0.7430,  0.7499,\n",
       "         0.6841,  0.9919,  0.3628,  0.4696,  0.4430,  0.4359,  0.9497,\n",
       "         0.1085,  0.2938,  0.1932,  0.4472,  0.2991,  0.6354,  0.5311,\n",
       "         0.8593,  0.1791,  0.9864,  0.6151,  0.2553,  0.2473,  0.8793,\n",
       "         0.8775,  0.5577,  0.2837,  0.2720,  0.2106,  0.2489,  0.5726,\n",
       "         0.4703,  0.5805,  0.9666,  0.6550,  0.2012,  0.4226,  0.6954,\n",
       "         0.2568,  0.1103,  0.8746,  0.1211,  0.3882,  0.4766,  0.4576,\n",
       "         0.3650,  0.1887,  0.5484,  0.4850,  0.9744,  0.5916,  0.4435,\n",
       "         0.2864,  0.7947,  0.4252,  0.3274,  0.6445,  0.9197,  0.1949,\n",
       "         0.2391,  0.8835,  0.3420,  0.5024,  0.8837,  0.2677,  0.9965,\n",
       "         0.5585,  0.1598,  0.1901,  0.3519,  0.5072,  0.7683,  0.1106,\n",
       "         0.8750,  0.8467,  0.9937,  0.1069,  0.4592,  0.6370,  0.2578,\n",
       "         0.3367,  0.6336,  0.7116,  0.3721,  0.4790,  0.8373,  0.2969,\n",
       "         0.6271,  0.6360,  0.8656,  0.2399,  0.8214,  0.8575,  0.8636,\n",
       "         0.5192,  0.5132,  0.7113,  0.1361,  0.2698,  0.1117,  0.9792,\n",
       "         0.3591,  0.4575,  0.8209,  0.6970,  0.9433,  0.1462,  0.2213,\n",
       "         0.6997,  0.8746,  0.6678,  0.5230,  0.6892,  0.6133,  0.3678,\n",
       "         0.2866,  0.7983,  0.3225,  0.7373,  0.8536,  0.4989,  0.3678,\n",
       "         0.2210,  0.1586,  0.8706,  0.7044,  0.9032,  0.1653,  0.2513,\n",
       "         0.8816,  0.8382,  0.9148,  0.9895,  0.8893,  0.7090,  0.2168,\n",
       "         0.1088,  0.9167,  0.6280,  0.3314,  0.8247,  0.1381,  0.6479,\n",
       "         0.9071,  0.1293,  0.8153,  0.6218,  0.8866,  0.9254,  0.2527,\n",
       "         0.1857,  0.5681,  0.6387,  0.9825,  0.4128,  0.6562,  0.2927,\n",
       "         0.7867,  0.6441,  0.9548,  0.8863,  0.6323,  0.7604,  0.1609,\n",
       "         0.8491,  0.8368,  0.8277,  0.7297,  0.6290,  0.8614,  0.2188,\n",
       "         0.1466,  0.4733,  0.9486,  0.3157,  0.3849,  0.1198,  0.1074,\n",
       "         0.4257,  0.9007,  0.9179,  0.4810,  0.4264,  0.9265,  0.8854,\n",
       "         0.3485,  0.4441,  0.4904,  0.1106,  0.2949,  0.3242,  0.8949,\n",
       "         0.1607,  0.5159,  0.4968,  0.2901,  0.9455,  0.5096,  0.6803,\n",
       "         0.4918,  0.1725,  0.7332,  0.3897,  0.8300,  0.1975,  0.5519,\n",
       "         0.9265,  0.4363,  0.6752,  0.6916,  0.9864,  0.9322,  0.9604,\n",
       "         0.1534,  0.9431,  0.7852,  0.7331,  0.6734,  0.1964,  0.4773,\n",
       "         0.7706,  0.5429,  0.6461,  0.6658,  0.8663,  0.3121,  0.4096,\n",
       "         0.3370,  0.9809,  0.9587,  0.1201,  0.1307,  0.8300,  0.8746,\n",
       "         0.6809,  0.6678,  0.4794,  0.8786,  0.2155,  0.5558,  0.8971,\n",
       "         0.5388,  0.5754,  0.3014,  0.2042,  0.9975,  0.2183,  0.2378,\n",
       "         0.9969,  0.1635,  0.4070,  0.7657,  0.5657,  0.2663,  0.6677,\n",
       "         0.9076,  0.5805,  0.8869,  0.9472,  0.6511,  0.1498,  0.3472,\n",
       "         0.1526,  0.4416,  0.6074,  0.3810,  0.7196,  0.1092,  0.4548,\n",
       "         0.3973,  0.6852,  0.7171,  0.9559,  0.1007,  0.9071,  0.4630,\n",
       "         0.6441,  0.2833,  0.1952,  0.9686,  0.4520,  0.7958,  0.5836,\n",
       "         0.2688,  0.5960,  0.9650,  0.5847,  0.5441,  0.1149,  0.4195,\n",
       "         0.7938,  0.4155,  0.9563,  0.5297,  0.9684,  0.8203,  0.9057,\n",
       "         0.1828,  0.1382,  0.1859,  0.6490,  0.6370,  0.3456,  0.9367,\n",
       "         0.4668,  0.4356,  0.6208,  0.1404,  0.9286,  0.2872,  0.9190,\n",
       "         0.6846,  0.8913,  0.7319,  0.9425,  0.9690,  0.1772,  0.9144,\n",
       "         0.1972,  0.7968,  0.7620,  0.1987,  0.4429,  0.9589,  0.8169,\n",
       "         0.5409,  0.6286,  0.9170,  0.2726,  0.1102,  0.7523,  0.3744,\n",
       "         0.9079,  0.3098,  0.4381,  0.1864,  0.4602,  0.4919,  0.3866,\n",
       "         0.9281,  0.6534,  0.4959,  0.5090,  0.1872,  0.9335,  0.4299,\n",
       "         0.3056,  0.2572,  0.2338,  0.4467,  0.3630,  0.6127,  0.1997,\n",
       "         0.1056,  0.9193,  0.5682,  0.6848,  0.8123,  0.6340,  0.4591,\n",
       "         0.5275,  0.2574,  0.2607,  0.9349,  0.7783,  0.7391,  0.7503,\n",
       "         0.4068,  0.1289,  0.5374,  0.2714,  0.6694,  0.7775,  0.2433,\n",
       "         0.5554,  0.7168,  0.2618,  0.6195,  0.5281,  0.3953,  0.3913,\n",
       "         0.1565,  0.7727,  0.8534,  0.5640,  0.3841,  0.2356,  0.1874,\n",
       "         0.8235,  0.2445,  0.4143,  0.6565,  0.8974,  0.3083,  0.3317,\n",
       "         0.7536,  0.8481,  0.8824,  0.5862,  0.8371,  0.5188,  0.3372,\n",
       "         0.6775,  0.2501,  0.3670,  0.8639,  0.6606,  0.4214,  0.7381,\n",
       "         0.2206,  0.3215,  0.1353,  0.7124,  0.8783,  0.1381,  0.4008,\n",
       "         0.6192,  0.4725,  0.1844,  0.1012,  0.1091])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer.transform(docs_test.data).todense().shape\n",
    "# docs_train.target\n",
    "# marg = marginal()\n",
    "# marg\n",
    "marg = marginal() \n",
    "marg[marg > 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 2, ..., 0, 5, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "marg = marg.numpy()\n",
    "# len(docs_test.target)\n",
    "cnt = 0\n",
    "for i in range(len(marg)):\n",
    "    if marg[i] == docs_train.target[i]:\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef model2(data):\\n    with pyro.iarange('data_loop', data.size(0)):\\n        cat_params = torch.tensor(np.ones((data.size(0), 6))*(1/6.))\\n        print(cat_params)\\n        cat = pyro.sample(\\n            'cat', \\n            dist.Categorical(cat_params).independent(1)\\n        )\\n        \\n        probs = _feature_prob_lookup[cat.numpy(), :]\\n        probs = torch.tensor(probs, dtype=torch.float32)\\n        probs = softplus(torch.tensor(probs), threshold=0)\\n\\n        return pyro.sample(\\n            'bern',\\n            dist.Bernoulli(probs).independent(1),\\n            obs=data\\n        )\\n    \\ndef model2_guide(data):\\n    with pyro.iarange('data_loop', data.size(0)):\\n        return pyro.sample(\\n            'cat', \\n            dist.Categorical(torch.tensor(np.ones((data.size(0), 6))*(1/6.))).independent(1)\\n        )\\n        \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def model2(data):\n",
    "    with pyro.iarange('data_loop', data.size(0)):\n",
    "        cat_params = torch.tensor(np.ones((data.size(0), 6))*(1/6.))\n",
    "        print(cat_params)\n",
    "        cat = pyro.sample(\n",
    "            'cat', \n",
    "            dist.Categorical(cat_params).independent(1)\n",
    "        )\n",
    "        \n",
    "        probs = _feature_prob_lookup[cat.numpy(), :]\n",
    "        probs = torch.tensor(probs, dtype=torch.float32)\n",
    "        probs = softplus(torch.tensor(probs), threshold=0)\n",
    "\n",
    "        return pyro.sample(\n",
    "            'bern',\n",
    "            dist.Bernoulli(probs).independent(1),\n",
    "            obs=data\n",
    "        )\n",
    "    \n",
    "def model2_guide(data):\n",
    "    with pyro.iarange('data_loop', data.size(0)):\n",
    "        return pyro.sample(\n",
    "            'cat', \n",
    "            dist.Categorical(torch.tensor(np.ones((data.size(0), 6))*(1/6.))).independent(1)\n",
    "        )\n",
    "        \"\"\"\n",
    "# datX = torch.tensor(vectors, dtype=torch.uint8)\n",
    "# posterior = pyro.infer.Importance(model2, model2_guide, num_samples=100)\n",
    "# posterior.run(torch.Tensor(vectors[0:100,:]))\n",
    "# model2(torch.Tensor(vectors[0:2,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncat = pyro.sample(\\n    'cat', \\n    dist.Categorical(torch.tensor(np.ones((10, 6))*(1/6.))).independent(1)\\n)\\nprint(cat.numpy())\\n_feature_prob_lookup[cat.numpy(), :]\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cat = pyro.sample(\n",
    "    'cat', \n",
    "    dist.Categorical(torch.tensor(np.ones((10, 6))*(1/6.))).independent(1)\n",
    ")\n",
    "print(cat.numpy())\n",
    "_feature_prob_lookup[cat.numpy(), :]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndirsample = pyro.sample(\\n    'dir', \\n    dist.Dirichlet(torch.tensor([1.,1.,1.,1.,1.,1.]))\\n)\\ntorch.ones(2,6) * dirsample\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "dirsample = pyro.sample(\n",
    "    'dir', \n",
    "    dist.Dirichlet(torch.tensor([1.,1.,1.,1.,1.,1.]))\n",
    ")\n",
    "torch.ones(2,6) * dirsample\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1381,  0.1600,  0.5901,  0.2140,  0.8927,  0.2165,  0.8071,\n",
       "         0.7297,  0.6904,  0.4891])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.sample('bern_prior', dist.Beta(torch.ones(10), torch.ones(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
